{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ear haarcascades\n",
    "left_cascade = cv.CascadeClassifier(\"./data/haarcascade_mcs_leftear.xml\")\n",
    "right_cascade = cv.CascadeClassifier(\"./data/haarcascade_mcs_rightear.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, bbox, color=(0, 255, 0)):\n",
    "    # Draw the ground truth, color is green by default\n",
    "    for x, y, w, h in bbox:\n",
    "\n",
    "        cv.rectangle(image, (x, y), (x+w, y+h), color, 2)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Anotate every corner of the rectangle with the coordinates, add some offset to coordinates\n",
    "        offset = -10 if color == (0, 255, 0) else 10\n",
    "        cv.putText(image, f\"{x}, {y}\", (x, y+offset), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        cv.putText(image, f\"{x+w}, {y}\", (x+w, y+offset), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        cv.putText(image, f\"{x}, {y+h}\", (x, y+h+offset), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        cv.putText(image, f\"{x+w}, {y+h}\", (x+w, y+h+offset), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \"\"\"\n",
    "\n",
    "    return image\n",
    "\n",
    "def store_image(image, rectangle, path):\n",
    "    # Crop image to the rectangle\n",
    "    x, y, w, h = rectangle\n",
    "    image = image[y:y+h, x:x+w]\n",
    "    \n",
    "    # Save the image\n",
    "    cv.imwrite(path, image)\n",
    "\n",
    "def calculate_iou(bb1, bb2):\n",
    "    \"\"\"Calculate IOU between two bounding boxes.\n",
    "    Format of bounding boxes: [x, y, w, h]\n",
    "    \"\"\"\n",
    "    # Get the coordinates of the bounding boxes\n",
    "    x1, y1, w1, h1 = bb1[0]\n",
    "    x2, y2, w2, h2 = 0, 0, 0, 0\n",
    "    for ear in bb2:\n",
    "        for x, y, w, h in ear:\n",
    "            x2, y2, w2, h2 = x, y, w, h\n",
    "\n",
    "    # Calculate the intersection area, x1 and y1 are the top left coordinates\n",
    "    x_left = max(x1, x2)\n",
    "    y_bottom = max(y1, y2)\n",
    "    x_right = min(x1+w1, x2+w2)\n",
    "    y_top = min(y1+h1, y2+h2)\n",
    "    \n",
    "    # Calculate the intersection area\n",
    "    intersection_area = abs(max((x_right - x_left, 0)) * max((y_top - y_bottom), 0))\n",
    "\n",
    "    # Calculate the union area\n",
    "    boxAArea = abs(w1 * h1)\n",
    "    boxBArea = abs(w2 * h2)\n",
    "\n",
    "    union_area = float(boxAArea + boxBArea - intersection_area)\n",
    "\n",
    "    # Calculate the IOU\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return round(iou, 4)\n",
    "\n",
    "\n",
    "def get_gt(image, name, data_path):\n",
    "    # Read the parameters from the txt file\n",
    "    # id, ear_center_x/image_width, ear_center_y/image_height, ear_width/image_width, ear_height/image_height\n",
    "        \n",
    "    # Get the connected image parameters\n",
    "    txt_file = [file for file in os.listdir(\n",
    "        data_path) if file.startswith(name) and file.endswith(\".txt\")][0]\n",
    "\n",
    "    # Get image width and height\n",
    "    image_width = image.shape[1]\n",
    "    image_height = image.shape[0]\n",
    "\n",
    "    with open(os.path.join(data_path, txt_file), \"r\") as f:\n",
    "        _, center_x, center_y, width, height = f.readlines()[0].split(\" \")\n",
    "        ear_width = int(float(width) * image_width)\n",
    "        ear_height = int(float(height) * image_height)\n",
    "        start_x = int(float(center_x) * image_width - ear_width/2)\n",
    "        start_y = int(float(center_y) * image_height - ear_height/2)\n",
    "        return [[start_x, start_y, ear_width, ear_height]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viola_jones(gt, curr_image, scaleFact=1.05, minNeigh=5, save_image=False, name=\"\"):\n",
    "    \"\"\"\n",
    "    Function for detecting ears using Viola-Jones algorithm. Returns the IOU for the detected ears.\n",
    "    @param gt: Ground truth bounding box coordinates\n",
    "    @param curr_image: Current image\n",
    "    @param scaleFact: Scale factor for the algorithm\n",
    "    @param minNeigh: Minimum neighbors for the algorithm\n",
    "    @param save_image: Boolean for saving the image, if true, save cropped ear for detected ears and gt\n",
    "    @param name: Name of the image\n",
    "    \"\"\"\n",
    "\n",
    "    if save_image:\n",
    "        # Save the ground truth\n",
    "        store_image(curr_image, gt[0], f'./data/work/VJ/gt/gt_{name}')\n",
    "\n",
    "    # Detect ears, returns x, y, w, h\n",
    "    ears = [left_cascade.detectMultiScale(curr_image, scaleFactor=scaleFact, minNeighbors=minNeigh),\n",
    "            right_cascade.detectMultiScale(curr_image, scaleFactor=scaleFact, minNeighbors=minNeigh)]\n",
    "    \n",
    "    # Continue if none of the ears are detected\n",
    "    if len(ears[0]) == 0 and len(ears[1]) == 0:\n",
    "        #print(f\"No ears detected for image {name}\")\n",
    "        return 0, \"Not detected\"\n",
    "    \n",
    "    # Iterate ears array which contains subarrays with the coordinates of the ears\n",
    "    for ear in ears:\n",
    "        # Iterate the coordinates of the ears\n",
    "        for x, y, w, h in ear:\n",
    "            # Draw the bounding box\n",
    "            if save_image:\n",
    "                # Save the detected ear\n",
    "                store_image(curr_image, (x, y, w, h), f'./data/work/VJ/detected/{name}')\n",
    "            pass\n",
    "\n",
    "    return calculate_iou(gt, ears), \"Detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vj_iou(image_objects, scaleFact=1.05, minNeigh=5):\n",
    "    \"\"\"\n",
    "    Runner function for calculating the IOU for Viola-Jones algorithm for all images in the dataset.\n",
    "    \"\"\"\n",
    "    # Create a dictionary for storing the results\n",
    "    image_objects_iou = {}\n",
    "\n",
    "    for name, (curr_image, gt) in tqdm(image_objects.items()):\n",
    "        # Run a default Viola-Jones algorithm\n",
    "        image_iou, status = viola_jones(gt, curr_image, scaleFact, minNeigh, save_image=True, name=name)\n",
    "\n",
    "        # Store the IOU\n",
    "        image_objects_iou[name] = (image_iou, status)\n",
    "    \n",
    "    return image_objects_iou\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vj_parameters(gts, images):\n",
    "    vj_iou_scaleFactor =defaultdict(list)\n",
    "    vj_iou_minNeigh =defaultdict(list)\n",
    "\n",
    "    vj_iou_together = defaultdict(list)\n",
    "    for gt, curr_image in tqdm(zip(gts, images)):\n",
    "        # Get the Viola-Jones result for multiple parameters\n",
    "        for scaleFact in np.arange(1.05, 1.4, 0.05):\n",
    "            scaleFact = round(scaleFact, 2)\n",
    "            for minNeigh in range(4, 9, 1):\n",
    "                iou = viola_jones(gt, curr_image, scaleFact, minNeigh)\n",
    "                # Skip if no ears are detected\n",
    "                vj_iou_scaleFactor[scaleFact].append(iou)\n",
    "                vj_iou_minNeigh[int(minNeigh)].append(iou)\n",
    "                vj_iou_together[f\"SF{scaleFact}_MN{minNeigh}\"].append(iou)\n",
    "                # Plot the IOU for each scale factor, x axis is the scale factor key and y axis is the IOU averaged for each scale factor\n",
    "    \n",
    "\n",
    "    # Create a single plot with xlabels being vj_iou_together keys and y axis being the mean IOU for each key, taking first value\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # Plot the IOU for each scale factor, x axis is the scale factor key and y axis is the IOU averaged for each scale factor\n",
    "    ax.plot(vj_iou_together.keys(), [np.mean([iou for iou, _ in value]) for value in vj_iou_together.values()])\n",
    "\n",
    "    # Rotate the xticks\n",
    "    plt.xticks(rotation=75)\n",
    "\n",
    "    # Decrease font size\n",
    "    plt.xticks(fontsize=8)\n",
    "\n",
    "    # Add a grid\n",
    "    plt.grid(True, alpha=0.4)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Scale factor and min neighbors\")\n",
    "    plt.ylabel(\"IOU\")\n",
    "    plt.title(\"Average IOU for each scale factor and min neighbors\")\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(\"./data/plots/IOU_scaleFactor_minNeigh.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images for running VJ\n",
    "data_path = \"./data/ears\"\n",
    "\n",
    "# Get images\n",
    "image_names = [file for file in os.listdir(data_path) if file.endswith(\".png\")]\n",
    "\n",
    "# Convert the images to cv objects\n",
    "image_objects = [cv.imread(os.path.join(data_path, image)) for image in image_names]\n",
    "\n",
    "# Get the ground truths\n",
    "gts = [get_gt(image, name.split(\".\")[0], data_path) for name, image in zip(image_names, image_objects)]\n",
    "\n",
    "# Create a dict for images, key is image name, value is a list of it's cv object and gt\n",
    "image_object_dict = {name: [image, gt] for name, image, gt in zip(image_names, image_objects, gts)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing various VJ parameters for different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Randomly sample n images for testing\n",
    "random_images = np.random.choice(list(image_object_dict.keys()), 500, replace=False)\n",
    "\n",
    "\n",
    "# Get the images and gts for the random images\n",
    "random_image_objects = [image_object_dict[image][0] for image in random_images]\n",
    "random_gts = [image_object_dict[image][1] for image in random_images]\n",
    "\n",
    "# Run the testing for the random images\n",
    "#test_vj_parameters(random_gts, random_image_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:23<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "image_objects_test = {key: value for key, value in list(image_object_dict.items())[:n]} \n",
    "image_objects_iou = calculate_vj_iou(image_objects_test, scaleFact=1.05, minNeigh=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 500\n",
      "Number of images detected: 241\n",
      "Average IOU for detected images: 0.515\n",
      "Average IOU for all images: 0.2482\n",
      "Number of false positives: 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNumber of images: 500\\nNumber of images detected: 221\\nAverage IOU for detected images: 0.5492\\nAverage IOU for all images: 0.2427\\nNumber of false positives: 32\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of images \n",
    "print(f\"Number of images: {len(image_objects_iou)}\")\n",
    "\n",
    "# Count how many were not detected\n",
    "nd = [iou for iou in image_objects_iou.values() if iou[1] == \"Detected\"]\n",
    "print(f\"Number of images detected: {len(nd)}\")\n",
    "\n",
    "# Print average IOU if detected\n",
    "iou = [iou for iou in image_objects_iou.values() if iou[1] == \"Detected\"]\n",
    "print(f\"Average IOU for detected images: {round(np.mean([iou[0] for iou in iou]), 4)}\")\n",
    "\n",
    "# Print average IOU for all images\n",
    "iou = [iou[0] for iou in image_objects_iou.values()]\n",
    "print(f\"Average IOU for all images: {round(np.mean(iou), 4)}\")\n",
    "\n",
    "# Print number of false positives\n",
    "fp = [iou for iou in image_objects_iou.values() if iou[0] == 0 and iou[1] == \"Detected\"]\n",
    "print(f\"Number of false positives: {len(fp)}\")\n",
    "\n",
    "\n",
    "# Results for VJ\n",
    "\"\"\"\n",
    "# Scale factor 1.05, min neighbors 5\n",
    "Number of images: 500\n",
    "Number of images detected: 221\n",
    "Average IOU for detected images: 0.5492\n",
    "Average IOU for all images: 0.2427\n",
    "Number of false positives: 32\n",
    "\n",
    "# Scale factor 1.05, min neighbors 4\n",
    "Number of images: 500\n",
    "Number of images detected: 241\n",
    "Average IOU for detected images: 0.515\n",
    "Average IOU for all images: 0.2482\n",
    "Number of false positives: 47\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBP\n",
    "Use LBP to calculate distance between detected cropped regions and GT cropped regions of ears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distances(sim_scores, name=\"\"):\n",
    "    # Print average cosine similarity\n",
    "    cos_sim = [sim for sim, _ in sim_scores.values()]\n",
    "\n",
    "    # Print average euclidean distance\n",
    "    euclidean_dist = [dist for _, dist in sim_scores.values()]\n",
    "\n",
    "    print(f\"Average cosine similarity for {name}: {round(np.mean(cos_sim), 4)}, euclidean distance: {round(np.mean(euclidean_dist), 4)}\")\n",
    "    #print(f\"Average euclidean distance for {name}: {round(np.mean(euclidean_dist), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lbp_custom(names, images):\n",
    "    # Convert image to grayscale -> iterate every pixel -> get the 8 neighbors -> compare the neighbors with the center pixel\n",
    "\n",
    "    lbps = {}\n",
    "    for name, image in tqdm(zip(names,images)):\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Initialize the LBP result\n",
    "        lbp_result = np.zeros_like(gray, dtype=np.uint8)\n",
    "\n",
    "        # Define the 8 neighbors for each pixel\n",
    "        neighbors = [(0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0), (-1, 1)]\n",
    "\n",
    "        # Calculate LBP for each pixel\n",
    "        rows, cols = gray.shape\n",
    "        for i in range(1, rows - 1):\n",
    "            for j in range(1, cols - 1):\n",
    "                binary_pattern = ''\n",
    "                center_value = gray[i, j]\n",
    "\n",
    "                for neighbor in neighbors:\n",
    "                    ni, nj = i + neighbor[0], j + neighbor[1]\n",
    "                    binary_pattern += '1' if gray[ni, nj] >= center_value else '0'\n",
    "\n",
    "                # Convert binary pattern to decimal and assign it to the result\n",
    "                lbp_result[i, j] = int(binary_pattern, 2)\n",
    "        lbps[name] = lbp_result\n",
    "\n",
    "    return lbps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lbp_custom_improve(names, images,radius=1, num_neighbors=8):\n",
    "    lbps = {}\n",
    "    for name, image in tqdm(zip(names, images)):\n",
    "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        lbp_result = np.zeros_like(gray, dtype=np.uint8)\n",
    "        neighbors = []  # Calculate circular neighbors for a given radius and number of neighbors\n",
    "        for k in range(num_neighbors):\n",
    "            x = int(-radius * np.sin(2.0 * np.pi * k / num_neighbors))\n",
    "            y = int(radius * np.cos(2.0 * np.pi * k / num_neighbors))\n",
    "            neighbors.append((x, y))\n",
    "\n",
    "        rows, cols = gray.shape\n",
    "        for i in range(radius, rows - radius):\n",
    "            for j in range(radius, cols - radius):\n",
    "                binary_pattern = ''\n",
    "                center_value = gray[i, j]\n",
    "                for neighbor in neighbors:\n",
    "                    ni, nj = i + neighbor[0], j + neighbor[1]\n",
    "                    binary_pattern += '1' if gray[ni, nj] >= center_value else '0'\n",
    "\n",
    "                decimal_value = int(binary_pattern, 2)\n",
    "                # Implement Uniform LBP\n",
    "                num_transitions = sum(1 for x, y in zip(binary_pattern, binary_pattern[1:] + binary_pattern[0]) if x != y)\n",
    "                if num_transitions <= 2:\n",
    "                    lbp_result[i, j] = decimal_value | np.left_shift(1, num_neighbors)  # Mark uniform patterns\n",
    "                lbp_result[i, j] = decimal_value\n",
    "\n",
    "        # Create histogram of LBP\n",
    "        hist, _ = np.histogram(lbp_result, bins=np.arange(0, 2**(num_neighbors+1), 1))\n",
    "        lbps[name] = hist / np.sum(hist)  # Normalize histogram\n",
    "\n",
    "    return lbps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compare_cropped_lbps(detected, gt):\n",
    "    \"\"\"\n",
    "    Compare LBPs of two images\n",
    "    @param detected: Detected image dict {name:lbp}\n",
    "    @param gt: Ground truth image dict {name:lbp}\n",
    "    \"\"\" \n",
    "\n",
    "    similarity_scores = {}\n",
    "\n",
    "    for (name, det), gt in tqdm(zip(detected.items(), gt.values())):\n",
    "        # Transform the images to a one-dimensional vector\n",
    "        det = det.flatten()\n",
    "        gt = gt.flatten()\n",
    "\n",
    "        # Calculate the cosine similarity\n",
    "        cos_similarity = cosine_similarity(det.reshape(1, -1), gt.reshape(1, -1))\n",
    "\n",
    "        # Calculate euclidean distance\n",
    "        euclidean_dist = euclidean(det, gt)\n",
    "\n",
    "        #print(f\"Image {name} cosine similarity: {cos_similarity}, euclidean distance: {euclidean_dist}\")\n",
    "\n",
    "        similarity_scores[name] = (cos_similarity, euclidean_dist)\n",
    "    \n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/work/VJ/\"\n",
    "\n",
    "# Get detected images\n",
    "detected_images = [file for file in os.listdir(data_path+\"detected\")]\n",
    "image_names = [image.split(\".\")[0]+\"\" for image in detected_images]\n",
    "# Get their GT images\n",
    "gt_images = [file for file in os.listdir(data_path+\"gt\") if file.split(\"_\")[-1] in detected_images]\n",
    "\n",
    "# Load the images, scale them to 128x128\n",
    "detected_image_objects = [cv.resize(cv.imread(os.path.join(data_path+\"detected\", image)), (128, 128)) for image in detected_images]\n",
    "gt_image_objects = [cv.resize(cv.imread(os.path.join(data_path+\"gt\", image)), (128, 128)) for image in gt_images]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:08, 26.83it/s]\n",
      "221it [00:08, 26.74it/s]\n",
      "221it [00:00, 1163.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity for custom LBP: 0.7692, euclidean distance: 18273.3273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate LBP for both lists\n",
    "detected_lbps = calculate_lbp_custom(image_names, detected_image_objects)\n",
    "gt_lbps = calculate_lbp_custom(image_names, gt_image_objects)\n",
    "\n",
    "sim_scores = compare_cropped_lbps(detected_lbps, gt_lbps)\n",
    "\n",
    "calculate_distances(sim_scores, \"custom LBP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom implementation with additional improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detected_image_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:15, 14.49it/s]\n",
      "221it [00:15, 14.25it/s]\n",
      "221it [00:00, 2540.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity for custom LBP with uniform patterns, histogram for radius = 1: 0.961, euclidean distance: 0.0702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:18, 12.17it/s]\n",
      "221it [00:18, 12.07it/s]\n",
      "221it [00:00, 2662.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity for custom LBP with uniform patterns, histogram for radius = 2: 0.9351, euclidean distance: 0.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:17, 12.58it/s]\n",
      "221it [00:17, 12.77it/s]\n",
      "221it [00:00, 2630.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity for custom LBP with uniform patterns, histogram for radius = 3: 0.9407, euclidean distance: 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for radius in [1, 2, 3]:\n",
    "    detected_lbps = calculate_lbp_custom_improve(image_names, detected_image_objects, radius=radius)\n",
    "    gt_lbps = calculate_lbp_custom_improve(image_names, gt_image_objects, radius=radius)\n",
    "    sim_scores = compare_cropped_lbps(detected_lbps, gt_lbps)\n",
    "    calculate_distances(sim_scores, \"custom LBP with uniform patterns, histogram for radius = \"+str(radius))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:00, 1257.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity for scikit LBP with radius 1: 0.8718, euclidean distance: 324.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:00, 1389.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity for scikit LBP with radius 2: 0.8372, euclidean distance: 756.4613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:00, 1398.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity for scikit LBP with radius 3: 0.8235, euclidean distance: 1244.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from skimage import feature\n",
    "\n",
    "# Use scikit LBP\n",
    "\n",
    "for radius in [1, 2, 3]:\n",
    "    # Calculate LBP for both lists, convert to gray first, create dict\n",
    "    detected_lbps = {name: feature.local_binary_pattern(cv.cvtColor(image, cv.COLOR_BGR2GRAY), radius*8, radius, method='uniform') for name,image in zip(image_names, detected_image_objects)}\n",
    "    gt_lbps = {name: feature.local_binary_pattern(cv.cvtColor(image, cv.COLOR_BGR2GRAY), radius*8, radius, method='uniform') for name,image in zip(image_names, gt_image_objects)}\n",
    "\n",
    "    sim_scores = compare_cropped_lbps(detected_lbps, gt_lbps)\n",
    "    calculate_distances(sim_scores, name=\"scikit LBP with radius \" + str(radius))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel-to-pixel comparison of base images only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:00, 818.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity for Pixel to pixel comparison: 0.9131, euclidean distance: 33577.2453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check only pixels\n",
    "\n",
    "detected = {name: image for name, image in zip(image_names, detected_image_objects)}\n",
    "gt = {name: image for name, image in zip(image_names, gt_image_objects)}\n",
    "\n",
    "sim_scores = compare_cropped_lbps(detected, gt)\n",
    "calculate_distances(sim_scores, name=\"Pixel to pixel comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mahotas implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:02, 91.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity for mahotas implementation 3: 0.9715, euclidean distance: 815.7983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import mahotas\n",
    "\n",
    "numPoints = 24\n",
    "radius = 3\n",
    "\n",
    "detected_lbps = {name: mahotas.features.lbp(cv.cvtColor(image, cv.COLOR_BGR2GRAY), radius, numPoints) for name,image in zip(image_names, detected_image_objects)}\n",
    "gt_lbps = {name: mahotas.features.lbp(cv.cvtColor(image, cv.COLOR_BGR2GRAY), radius, numPoints) for name,image in zip(image_names, gt_image_objects)}\n",
    "\n",
    "sim_scores = compare_cropped_lbps(detected_lbps, gt_lbps)\n",
    "calculate_distances(sim_scores, name=\"mahotas implementation \" + str(radius))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionnaire\n",
    "Scale factor 1.05, min neighbors 5 Number of images: 500 Number of images detected: 221 Average IOU for detected images: 0.5492 Average IOU for all images: 0.2427 Number of false positives: 32\n",
    "____\n",
    "\n",
    "Average cosine similarity for custom LBP: 0.7692, euclidean distance: 18273.3273; Average cosine similarity for custom LBP with uniform patterns, histogram for radius = 1: 0.961, euclidean distance: 0.0702; Average cosine similarity for scikit LBP with radius 1: 0.8718, euclidean distance: 324.9986; Average cosine similarity for Pixel to pixel comparison: 0.9131, euclidean distance: 33577.2453; Average cosine similarity for mahotas implementation 3: 0.9715, euclidean distance: 815.7983\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "___\n",
    "I did not split the dataset. \n",
    "\n",
    "___\n",
    "\n",
    "For VJ i optimized two parameters, scaleFactor and minNeighbors. I ran the VJ detection program with a range of values for both parameters and plotted the graph, scoring average IOU and considering false positives. I found out that for VJ, best parameters are scaleFactor=1.05 and minNeighbors=4 or 5 (4 has better IOU, 5 has less false positives)\n",
    "\n",
    "___\n",
    "\n",
    "I implemented next upgrades: - Different radii: I implemented the LBP algorithm so that it takes a parameter for radius with which I calculated where to start and stop the LBP iteration and calculate how long the value from neighbors is; - uniform LBP: i check the binarry pattern for every pixel and count the bit transitions for adjacent pixels. if the number is 2 or less, i add a specific bit that indicates an uniform pattern; -histogram: after calculating LBP, i created a histogram of these values and then normalized it by its sum. This represented the frequency off occurances of each pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
